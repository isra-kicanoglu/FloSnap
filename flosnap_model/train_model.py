import torch
import os
from transformers import CLIPModel, CLIPProcessor
import torch.nn as nn
from PIL import Image
import json
from torch.utils.data import Dataset, DataLoader
from itertools import chain

# Sabitler
MODEL_PATH = "./finetuned_clip_model"
DATASET_FILE = "ayakkabilar.jsonl"
IMAGES_FOLDER = os.path.join("..", "ayakkabi_scraper", "ayakkabi_resimleri")
SAVE_PATH = "./finetuned_clip_with_logos"

# AyakkabÄ± Veri Seti SÄ±nÄ±fÄ±
# Bu sÄ±nÄ±f, ayakkabilar.jsonl dosyasÄ±nÄ± okuyarak veri setini hazÄ±rlar.
class AyakkabiDataset(Dataset):
    def __init__(self, file_path, processor, images_folder):
        self.processor = processor
        self.images_folder = images_folder
        self.data = []
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                self.data.append(json.loads(line))
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        item = self.data[idx]
        image_urls = item.get('image_urls', [])
        brand = item.get('brand')
        
        processed_images = []
        
        if image_urls and brand:
            for image_relative_path in image_urls:
                # ÃœrÃ¼n ID'sini ve dosya adÄ±nÄ± al
                product_id = os.path.basename(os.path.dirname(image_relative_path))
                image_name = os.path.basename(image_relative_path)
                
                # DoÄŸru dosya yolunu oluÅŸtur
                image_path = os.path.join(self.images_folder, product_id, image_name)
                
                if os.path.exists(image_path):
                    try:
                        image = Image.open(image_path).convert("RGB")
                        processed_images.append(image)
                    except Exception as e:
                        print(f"Resim yÃ¼klenirken hata oluÅŸtu: {image_path}. Hata: {e}")
            
            if processed_images:
                # Hem gÃ¶rsel hem de metin (marka) iÃ§in veriyi hazÄ±rla
                inputs = self.processor(
                    text=brand,
                    images=processed_images,
                    return_tensors="pt",
                    padding=True
                )
                inputs['input_ids'] = inputs['input_ids'].squeeze(0)
                # Resim vektÃ¶rlerinin ortalamasÄ±nÄ± al
                inputs['pixel_values'] = inputs['pixel_values'].mean(dim=0).unsqueeze(0)
                return inputs

        return None

# Toplu Ä°ÅŸlem Fonksiyonu
def collate_fn(batch):
    batch = [item for item in batch if item is not None]
    if not batch:
        return None
    
    inputs = {key: [d[key] for d in batch] for key in batch[0]}
    
    for key in inputs:
        # Metin girdileri iÃ§in yÄ±ÄŸÄ±nlama
        if key == 'input_ids':
            inputs[key] = torch.stack(inputs[key])
        # Resim girdileri iÃ§in boyutlandÄ±rma ve yÄ±ÄŸÄ±nlama
        else:
            inputs[key] = torch.cat(inputs[key], dim=0)

    return inputs

# Model eÄŸitimi
def train_model():
    print("Mevcut model yÃ¼kleniyor...")
    try:
        model = CLIPModel.from_pretrained(MODEL_PATH)
        processor = CLIPProcessor.from_pretrained(MODEL_PATH)
        
        device = "cuda" if torch.cuda.is_available() else "cpu"
        model.to(device)

        dataset = AyakkabiDataset(DATASET_FILE, processor, IMAGES_FOLDER)
        dataloader = DataLoader(dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)

        optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)

        print("Modelin markalarÄ± Ã¶ÄŸrenmesi iÃ§in ince ayar (fine-tuning) baÅŸlatÄ±lÄ±yor...")
        
        num_epochs = 1
        model.train()
        
        for epoch in range(num_epochs):
            for batch in dataloader:
                if batch is None:
                    continue
                
                optimizer.zero_grad()
                
                inputs = {k: v.to(device) for k, v in batch.items()}
                outputs = model(**inputs)
                loss = outputs.loss
                
                loss.backward()
                optimizer.step()
                
                print(f"Epoch: {epoch+1}, KayÄ±p (Loss): {loss.item():.4f}")

        if not os.path.exists(SAVE_PATH):
            os.makedirs(SAVE_PATH)
        
        # Hem modeli hem de iÅŸlemciyi kaydet
        model.save_pretrained(SAVE_PATH)
        processor.save_pretrained(SAVE_PATH)
        
        print("\nModel baÅŸarÄ±yla eÄŸitildi ve yeni klasÃ¶re kaydedildi! ğŸ‰")
        print(f"Yeni modelin konumu: {SAVE_PATH}")

    except Exception as e:
        print(f"Model eÄŸitimi sÄ±rasÄ±nda bir hata oluÅŸtu: {e}")

train_model()
